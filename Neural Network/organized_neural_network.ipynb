{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSBfoTbxl5xH"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('AHDBase_TrainingSet.csv')\n",
    "data_cols = list(data.columns)\n",
    "data_cols.remove('Unnamed: 0')\n",
    "train_data = data[data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.644330</td>\n",
       "      <td>0.324742</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.159794</td>\n",
       "      <td>0.159794</td>\n",
       "      <td>0.335052</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355670</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355670</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.85098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.849765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.652582</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5        6    7  \\\n",
       "0  0.890196  0.000000  0.000000  0.223529  0.776471  1.000000  1.00000  1.0   \n",
       "1  0.644330  0.324742  0.175258  0.159794  0.159794  0.335052  1.00000  1.0   \n",
       "2  1.000000  1.000000  0.800000  0.349020  0.203922  0.203922  0.85098  1.0   \n",
       "3  1.000000  1.000000  0.976471  0.141176  0.321569  1.000000  1.00000  1.0   \n",
       "4  0.000000  0.849765  1.000000  1.000000  0.938967  0.985915  1.00000  1.0   \n",
       "\n",
       "          8         9  ...          55        56        57        58  \\\n",
       "0  0.890196  0.000000  ...    1.000000  0.443137  0.000000  0.000000   \n",
       "1  0.355670  0.927835  ...    0.067010  1.000000  1.000000  1.000000   \n",
       "2  1.000000  0.741176  ...    0.223529  1.000000  0.909804  0.478431   \n",
       "3  1.000000  1.000000  ...    0.564706  0.180392  0.360784  1.000000   \n",
       "4  0.450704  0.253521  ...    1.000000  1.000000  1.000000  1.000000   \n",
       "\n",
       "         59        60        61        62        63  label  \n",
       "0  0.223529  0.776471  1.000000  1.000000  1.000000      0  \n",
       "1  1.000000  1.000000  1.000000  1.000000  0.355670      6  \n",
       "2  0.235294  0.082353  0.101961  0.274510  0.866667      5  \n",
       "3  1.000000  1.000000  1.000000  0.788235  0.090196      8  \n",
       "4  1.000000  1.000000  1.000000  0.633803  0.652582      3  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('AHDBase_TestingSet.csv')\n",
    "data_cols = list(data.columns)\n",
    "data_cols.remove('Unnamed: 0')\n",
    "test_data = data[data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.189427</td>\n",
       "      <td>0.788546</td>\n",
       "      <td>0.960352</td>\n",
       "      <td>0.951542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898678</td>\n",
       "      <td>0.674009</td>\n",
       "      <td>0.942731</td>\n",
       "      <td>0.264317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951542</td>\n",
       "      <td>0.330396</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.396078  0.000000  0.164706  0.694118  1.000000  1.000000   \n",
       "1  1.000000  1.000000  1.000000  0.243137  0.000000  0.000000  0.192157   \n",
       "2  0.800000  0.549020  0.298039  1.000000  1.000000  1.000000  1.000000   \n",
       "3  0.189427  0.788546  0.960352  0.951542  1.000000  1.000000  0.898678   \n",
       "4  1.000000  1.000000  0.956863  0.600000  0.223529  0.109804  0.149020   \n",
       "\n",
       "          7         8         9  ...          55        56        57  \\\n",
       "0  1.000000  0.639216  0.015686  ...    1.000000  1.000000  0.847059   \n",
       "1  0.756863  1.000000  1.000000  ...    1.000000  0.549020  0.176471   \n",
       "2  1.000000  0.101961  0.349020  ...    1.000000  1.000000  1.000000   \n",
       "3  0.674009  0.942731  0.264317  ...    0.682819  1.000000  1.000000   \n",
       "4  0.909804  1.000000  0.980392  ...    0.847059  0.976471  0.576471   \n",
       "\n",
       "         58        59        60        61        62        63  label  \n",
       "0  0.411765  0.000000  0.450980  0.666667  1.000000  1.000000      0  \n",
       "1  0.321569  0.517647  0.839216  1.000000  1.000000  1.000000      1  \n",
       "2  0.501961  0.050980  0.298039  0.501961  0.549020  0.650980      4  \n",
       "3  1.000000  1.000000  1.000000  1.000000  0.951542  0.330396      3  \n",
       "4  0.200000  0.000000  0.062745  0.317647  0.784314  1.000000      5  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1552507361092,
     "user": {
      "displayName": "Faris Alasmary",
      "photoUrl": "",
      "userId": "17258654308117726454"
     },
     "user_tz": -180
    },
    "id": "493OSAGqmcwF",
    "outputId": "08f4b984-12e7-4a3e-8c1b-f2f7c84ccfe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is: 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a101102e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "output = 'label'\n",
    "features = list(train_data.columns)\n",
    "features.remove(output)\n",
    "\n",
    "image_with_label = train_data.iloc[65]\n",
    "\n",
    "label = image_with_label[output]\n",
    "image = image_with_label[features].values\n",
    "\n",
    "image = image.reshape(8, 8)\n",
    "\n",
    "print('The label is:', label)\n",
    "plt.imshow(image[0:64], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-ab9tv7pvYo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "binarizer = LabelBinarizer()\n",
    "one_hot_encoded_train_labels = binarizer.fit_transform(train_data[output])\n",
    "\n",
    "test_value = 3\n",
    "print(train_data[output][test_value])\n",
    "print(one_hot_encoded_train_labels[test_value])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[features].values\n",
    "y_train = one_hot_encoded_train_labels\n",
    "\n",
    "X_test = test_data[features].values\n",
    "y_test = binarizer.transform(test_data[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take transpose since the neural network considers columns as examples and rows as features\n",
    "# i.e. if m is the number of samples (images) and n is the number of features (image pixels), then \n",
    "# n x m is the shape that is accepted by the network\n",
    "X_train = X_train.T\n",
    "y_train = y_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60000)\n",
      "(10, 60000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1. / (1 + np.exp(-Z))\n",
    "\n",
    "def sigmoid_prime(A):\n",
    "    return A * (1 - A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mini_batches(X, y, batch_size):\n",
    "    assert X.shape[1] == y.shape[1], 'Size Mismatch'\n",
    "    m = X.shape[1]\n",
    "    num_of_mini_batches = m // batch_size\n",
    "\n",
    "    for i in range(num_of_mini_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        mini_bacth_X = X[:, start:end]\n",
    "        mini_batch_y = y[:, start:end]\n",
    "        yield mini_bacth_X, mini_batch_y\n",
    "\n",
    "    if m % batch_size != 0:\n",
    "        last_mini_bacth_X = X[:, end:]\n",
    "        last_mini_bacth_y = y[:, end:]\n",
    "        yield last_mini_bacth_X, last_mini_bacth_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_weights(layers):\n",
    "    parameters = {}\n",
    "    L = parameters['num_of_layers'] = len(layers) - 1 # since the input layer is include the input layer\n",
    "    \n",
    "    for i in range(L):\n",
    "        W = 2*np.random.random((layers[i + 1], layers[i])) - 1\n",
    "        W /= layers[i + 1]\n",
    "\n",
    "        b = 2*np.random.random((layers[i + 1], 1)) - 1\n",
    "        \n",
    "        parameters[f'W{i + 1}'] = W\n",
    "        parameters[f'b{i + 1}'] = b\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(X, parameters):\n",
    "    cache = {}\n",
    "    cache['A0'] = X\n",
    "    \n",
    "    for i in range(1, parameters['num_of_layers'] + 1):\n",
    "        W = parameters[f'W{i}']\n",
    "        b = parameters[f'b{i}']\n",
    "        A_prev = cache[f'A{i - 1}']\n",
    "        \n",
    "        Z = W.dot(A_prev) + b\n",
    "        A = sigmoid(Z)\n",
    "        \n",
    "        cache[f'A{i}'] = A\n",
    "        \n",
    "    y_pred = A\n",
    "    \n",
    "    return y_pred, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(y_true, y_pred, cache, parameters):\n",
    "    L = parameters['num_of_layers']\n",
    "    m = y_true.shape[1]\n",
    "    errors = {}\n",
    "    \n",
    "    errors[f'delta{L}'] = -(y_true - y_pred) * sigmoid_prime(y_pred)\n",
    "    \n",
    "    for i in range(L, 1, -1):\n",
    "        W = parameters[f'W{i}']\n",
    "        delta = errors[f'delta{i}']\n",
    "        A_prev = cache[f'A{i - 1}']\n",
    "        \n",
    "        delta_prev = W.T.dot(delta) * sigmoid_prime(A_prev)\n",
    "        errors[f'delta{i - 1}'] = delta_prev\n",
    "    \n",
    "    \n",
    "    gradients = {}\n",
    "    for i in range(1, L + 1):\n",
    "        delta = errors[f'delta{i}']\n",
    "        A_prev = cache[f'A{i - 1}']\n",
    "        \n",
    "        dW = delta.dot(A_prev.T) / m\n",
    "        \n",
    "        gradients[f'dW{i}'] = dW\n",
    "    \n",
    "    for i in range(1, L + 1):\n",
    "        delta = errors[f'delta{i}']\n",
    "        db = delta.sum(axis=1, keepdims=True) / m\n",
    "        gradients[f'db{i}'] = db\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, alpha):\n",
    "    L = parameters['num_of_layers']\n",
    "    for i in range(1, L + 1):\n",
    "        W = parameters[f'W{i}']\n",
    "        b = parameters[f'b{i}']\n",
    "        dW = gradients[f'dW{i}']\n",
    "        db = gradients[f'db{i}']\n",
    "        \n",
    "        W = W - alpha*dW\n",
    "        b = b - alpha*db\n",
    "    \n",
    "        parameters[f'W{i}'] = W\n",
    "        parameters[f'b{i}'] = b\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y_true, y_pred):\n",
    "    m = y_true.shape[1]\n",
    "    return 0.5 * np.sum((y_true - y_pred) ** 2) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(X, y, hidden_layers, alpha=0.9, batch_size=64, epochs=2000, parameters=None, verbose=100):\n",
    "    \n",
    "    layers = [X.shape[0]] + hidden_layers + [y.shape[0]]\n",
    "\n",
    "    if parameters == None:\n",
    "        parameters = initialize_weights(layers)\n",
    "    costs = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        ### Shuffling ###\n",
    "        indices = np.arange(X.shape[1])\n",
    "        np.random.shuffle(indices)\n",
    "        X = X[:, indices]\n",
    "        y = y[:, indices]\n",
    "        #################\n",
    "        total_cost = 0\n",
    "        j = 0\n",
    "        for mini_bacth_X, mini_bacth_y in get_mini_batches(X, y, batch_size):\n",
    "            m = mini_bacth_X.shape[1]\n",
    "            y_true = mini_bacth_y\n",
    "            y_pred, cache = feedforward(mini_bacth_X, parameters)\n",
    "\n",
    "            y_true = np.atleast_2d(y_true)\n",
    "            cost = compute_cost(y_true, y_pred)\n",
    "            total_cost += cost\n",
    "\n",
    "            gradients = backpropagation(y_true, y_pred, cache, parameters)\n",
    "\n",
    "            for i in range(1, parameters['num_of_layers'] + 1):\n",
    "                assert parameters[f'W{i}'].shape == gradients[f'dW{i}'].shape, 'Size Mismatch'\n",
    "                assert parameters[f'b{i}'].shape == gradients[f'db{i}'].shape, 'Size Mismatch'\n",
    "\n",
    "            # update weights\n",
    "            parameters = update_parameters(parameters=parameters, gradients=gradients, alpha=alpha)\n",
    "            j += 1\n",
    "\n",
    "        avg_cost = total_cost / j\n",
    "        costs.append(avg_cost)\n",
    "        \n",
    "        if epoch % verbose == 0:\n",
    "            print(epoch, avg_cost)\n",
    "    \n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.4500115550441033\n",
      "200 0.45001195632463403\n",
      "300 0.450009673225429\n",
      "400 0.45000949821572367\n",
      "500 0.450012247493987\n",
      "600 0.45000977516327023\n",
      "700 0.45001063042990114\n",
      "800 0.45001144713700064\n",
      "900 0.4500101207751126\n",
      "1000 0.45000975104612645\n",
      "1100 0.45001187085164607\n",
      "1200 0.45001070516065506\n",
      "1300 0.45000895671264757\n",
      "1400 0.4500111083565569\n",
      "1500 0.45001103994992125\n",
      "1600 0.4500105653064905\n",
      "1700 0.4500100302240186\n",
      "1800 0.45000974406785954\n",
      "1900 0.45000814850404147\n",
      "2000 0.45000950438850484\n",
      "2100 0.45000958270267777\n",
      "2200 0.45000982496836517\n",
      "2300 0.4500089098453699\n",
      "2400 0.4500107327518878\n",
      "2500 0.45001005892700907\n",
      "2600 0.4500105286773962\n",
      "2700 0.4500092251052109\n",
      "2800 0.45000975129098647\n",
      "2900 0.450008551903441\n",
      "3000 0.4500102552724172\n",
      "3100 0.45001008372157986\n",
      "3200 0.45000985280008643\n",
      "3300 0.45000932000018207\n",
      "3400 0.45000901521701714\n",
      "3500 0.45001014293636465\n",
      "3600 0.4500090744243674\n",
      "3700 0.4500086088500114\n",
      "3800 0.4500092928006922\n",
      "3900 0.4500087917947109\n",
      "4000 0.45000950389003264\n",
      "4100 0.4500096772103474\n",
      "4200 0.4500083432933606\n",
      "4300 0.450010304460615\n",
      "4400 0.45000949203053736\n",
      "4500 0.4500092127114263\n",
      "4600 0.450009120188462\n",
      "4700 0.4500089671552795\n",
      "4800 0.45000927043628186\n",
      "4900 0.45000815374435477\n",
      "5000 0.45000634640751136\n",
      "5100 0.45000950326661204\n",
      "5200 0.45000922781609176\n",
      "5300 0.45000906550499165\n",
      "5400 0.45000854757034525\n",
      "5500 0.45000830797742325\n",
      "5600 0.45000816044698416\n",
      "5700 0.450008099950097\n",
      "5800 0.45000783598853455\n",
      "5900 0.45000717553189434\n",
      "6000 0.4500065389658386\n",
      "6100 0.4500050675749512\n",
      "6200 0.4500031145040816\n",
      "6300 0.450000534940968\n",
      "6400 0.4499955401016503\n",
      "6500 0.44998433709626723\n",
      "6600 0.4499387053014807\n",
      "6700 0.44895293154713345\n",
      "6800 0.3416449210457146\n",
      "6900 0.24369816774769765\n",
      "7000 0.10130441839610599\n",
      "7100 0.04308819559058138\n",
      "7200 0.03201878628711476\n",
      "7300 0.0261437156211142\n",
      "7400 0.022844763796280115\n",
      "7500 0.020804906153491683\n",
      "7600 0.019397134228900492\n",
      "7700 0.018314531285808993\n",
      "7800 0.01738383158978401\n",
      "7900 0.01655478021238368\n",
      "8000 0.015819649860489043\n",
      "8100 0.015235594398845772\n",
      "8200 0.014685002472292517\n",
      "8300 0.014244744568456726\n",
      "8400 0.013837007591625719\n",
      "8500 0.013501064313213445\n",
      "8600 0.01319443934097886\n",
      "8700 0.012822302560443404\n",
      "8800 0.012499310498794712\n",
      "8900 0.012194972007759961\n",
      "9000 0.011940578446726236\n",
      "9100 0.011654903866844073\n",
      "9200 0.011429357455973309\n",
      "9300 0.011171567714027945\n",
      "9400 0.010984262627314896\n",
      "9500 0.010807998598312782\n",
      "9600 0.010632306333553606\n",
      "9700 0.010479485946492256\n",
      "9800 0.010311987702391324\n",
      "9900 0.010160329199970857\n",
      "10000 0.01003142720427656\n",
      "10100 0.009943626992606468\n",
      "10200 0.009838357891297436\n",
      "10300 0.00969894585184535\n",
      "10400 0.009672023478397426\n",
      "10500 0.009558633685414377\n",
      "10600 0.009503646341922047\n",
      "10700 0.009414654569670592\n",
      "10800 0.009358957421587046\n",
      "10900 0.009285028491629292\n",
      "11000 0.009206491834741605\n",
      "11100 0.009165947356483264\n",
      "11200 0.009072942578217039\n",
      "11300 0.009071059985948163\n",
      "11400 0.00903625629461218\n",
      "11500 0.009003198004389075\n",
      "11600 0.00894800692936967\n",
      "11700 0.008917044271412966\n",
      "11800 0.008872127670596329\n",
      "11900 0.008846671850251713\n",
      "12000 0.008809559940976215\n",
      "12100 0.008795482199999226\n",
      "12200 0.008755825870321294\n",
      "12300 0.008731703607479272\n",
      "12400 0.00870249024756727\n",
      "12500 0.00866334921726488\n",
      "12600 0.008664980048706729\n",
      "12700 0.008603904078618682\n",
      "12800 0.008597212547582524\n",
      "12900 0.008577363603246532\n",
      "13000 0.00854660198316081\n",
      "13100 0.0085229223573349\n",
      "13200 0.008512091144108608\n",
      "13300 0.008485993222478484\n",
      "13400 0.008477101982237101\n",
      "13500 0.008449649566793258\n",
      "13600 0.008442537838054005\n",
      "13700 0.008429802391604251\n",
      "13800 0.00840681161784105\n",
      "13900 0.008387511849485543\n",
      "14000 0.008395133609460969\n",
      "14100 0.008382426901334032\n",
      "14200 0.008359574660905717\n",
      "14300 0.00835321376518256\n",
      "14400 0.008338680749811976\n",
      "14500 0.008316445059414012\n",
      "14600 0.008366219828509129\n",
      "14700 0.00831789776330841\n",
      "14800 0.008280431167817185\n",
      "14900 0.00823744704981328\n",
      "15000 0.008212892142383419\n",
      "15100 0.008259131167080913\n",
      "15200 0.008198855529947657\n",
      "15300 0.008209926906012592\n",
      "15400 0.008180007362234155\n",
      "15500 0.00818847989505405\n",
      "15600 0.008172134757034108\n",
      "15700 0.008264150135216477\n",
      "15800 0.008177105600366406\n",
      "15900 0.00816739337072785\n",
      "16000 0.008163600295275526\n",
      "16100 0.008148584348676635\n",
      "16200 0.008146521328980019\n",
      "16300 0.008149362304338506\n",
      "16400 0.008122772817034968\n",
      "16500 0.00813779211794484\n",
      "16600 0.008146341251070853\n",
      "16700 0.008107702814346177\n",
      "16800 0.008101089452942915\n",
      "16900 0.008095303444416946\n",
      "17000 0.00810223589764535\n",
      "17100 0.008076227698210323\n",
      "17200 0.008050863031938896\n",
      "17300 0.008058044338793537\n",
      "17400 0.008057875824538964\n",
      "17500 0.008044780174969582\n",
      "17600 0.008040354304400792\n",
      "17700 0.008039301986107592\n",
      "17800 0.008021766429700221\n",
      "17900 0.008043641853170892\n",
      "18000 0.008009418197344513\n",
      "18100 0.00805172412257091\n",
      "18200 0.00798324454769655\n",
      "18300 0.007990322461018372\n",
      "18400 0.00798150494950434\n",
      "18500 0.007979126463129786\n",
      "18600 0.007989016664154438\n",
      "18700 0.00797761763983544\n",
      "18800 0.007974120259138405\n",
      "18900 0.007980365771140533\n",
      "19000 0.00798500784340798\n",
      "19100 0.007964699153707358\n",
      "19200 0.007977178785430757\n",
      "19300 0.007959305193541634\n",
      "19400 0.007967717039860392\n",
      "19500 0.007978486742220047\n",
      "19600 0.007971259188369205\n",
      "19700 0.007955560517517335\n",
      "19800 0.007953189605667573\n",
      "19900 0.007956305272765023\n",
      "20000 0.00793938020392731\n",
      "20100 0.007956909783488038\n",
      "20200 0.007961530660049277\n",
      "20300 0.007944613706398644\n",
      "20400 0.007954139516861464\n",
      "20500 0.007935987021919203\n",
      "20600 0.007954363895153327\n",
      "20700 0.007948331657158525\n",
      "20800 0.007928539122891825\n",
      "20900 0.007935698609728833\n",
      "21000 0.007926535270814892\n",
      "21100 0.007922434084906598\n",
      "21200 0.007919575405008638\n",
      "21300 0.007922992353917593\n",
      "21400 0.007925855720110874\n",
      "21500 0.007937389865802055\n",
      "21600 0.007930242598562119\n",
      "21700 0.007917744601190269\n",
      "21800 0.007916410351407461\n",
      "21900 0.007920991898137367\n",
      "22000 0.007937142627529582\n",
      "22100 0.007943075734442336\n",
      "22200 0.007923591455291796\n",
      "22300 0.00791353114258458\n",
      "22400 0.007926638273924562\n",
      "22500 0.007916305725858422\n",
      "22600 0.00791432676456478\n",
      "22700 0.007933240638132106\n",
      "22800 0.007921915397893052\n",
      "22900 0.007919964562831101\n",
      "23000 0.007903664133549064\n",
      "23100 0.007917352621273526\n",
      "23200 0.007908607257098445\n",
      "23300 0.007911618962684719\n",
      "23400 0.00789882128409108\n",
      "23500 0.007895732014177537\n",
      "23600 0.007877864735518566\n",
      "23700 0.00789322977351947\n",
      "23800 0.007889122292115757\n",
      "23900 0.007877096873944023\n",
      "24000 0.00787765443177519\n",
      "24100 0.00788935005625287\n",
      "24200 0.007876420886125852\n",
      "24300 0.007865339393599513\n",
      "24400 0.007872345240577984\n",
      "24500 0.007857103798366\n",
      "24600 0.0078607562500961\n",
      "24700 0.007842478508061104\n",
      "24800 0.007846673829383054\n",
      "24900 0.007846272769981379\n",
      "25000 0.007861317245414218\n",
      "25100 0.007843144857505799\n",
      "25200 0.007847891434701331\n",
      "25300 0.007844862374908688\n",
      "25400 0.007829360858668971\n",
      "25500 0.007836188020655206\n",
      "25600 0.007829390465091965\n",
      "25700 0.007827516792650998\n",
      "25800 0.007837425914678231\n",
      "25900 0.007846916499847197\n",
      "26000 0.007835481996739847\n",
      "26100 0.007818720772817372\n",
      "26200 0.007830337558850629\n",
      "26300 0.007817748705221917\n",
      "26400 0.007809139287431882\n",
      "26500 0.007815006761304975\n",
      "26600 0.00782351300152203\n",
      "26700 0.0078243227935242\n",
      "26800 0.007820970294912284\n",
      "26900 0.00781756580345896\n",
      "27000 0.007812417326656252\n",
      "27100 0.007802174050985112\n",
      "27200 0.007812382959798366\n",
      "27300 0.007810036539588261\n",
      "27400 0.007812495901118747\n",
      "27500 0.007808321300981771\n",
      "27600 0.007815620530282704\n",
      "27700 0.007804405941357122\n",
      "27800 0.007805854045737432\n",
      "27900 0.007808790107969261\n",
      "28000 0.0078120776300644075\n",
      "28100 0.007797692172425343\n",
      "28200 0.007797651833198927\n",
      "28300 0.007791643752726653\n",
      "28400 0.0077963856723237395\n",
      "28500 0.007804033678860335\n",
      "28600 0.007791062066451004\n",
      "28700 0.007804457321965507\n",
      "28800 0.007801186973695565\n",
      "28900 0.007807388106220928\n",
      "29000 0.007783744483531516\n",
      "29100 0.007784301894639491\n",
      "29200 0.007791527667639513\n",
      "29300 0.0077951920690397915\n",
      "29400 0.00778397663803332\n",
      "29500 0.007778993755695226\n",
      "29600 0.007781244257994644\n",
      "29700 0.00778084560137517\n",
      "29800 0.007784721652384934\n",
      "29900 0.007775792883961085\n",
      "30000 0.007782823502209491\n",
      "30100 0.007786861063746136\n",
      "30200 0.007773913521467024\n",
      "30300 0.007788953014710834\n",
      "30400 0.007780383007920954\n",
      "30500 0.007774251541730387\n",
      "30600 0.0077870829670343795\n",
      "30700 0.007772889367569429\n",
      "30800 0.0077788206931915845\n",
      "30900 0.007784370338048599\n",
      "31000 0.007786055237550596\n",
      "31100 0.007792595295970384\n",
      "31200 0.007778254127076115\n",
      "31300 0.007763327108913291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31400 0.0077713712804894875\n",
      "31500 0.007780326646765279\n",
      "31600 0.007761903034105468\n",
      "31700 0.007763252081157591\n",
      "31800 0.007766995106447531\n",
      "31900 0.007766023361404491\n",
      "32000 0.007767704417612842\n",
      "32100 0.007779429423503751\n",
      "32200 0.007758223202119684\n",
      "32300 0.007764838333260315\n",
      "32400 0.007767247967793823\n",
      "32500 0.007756913355616907\n",
      "32600 0.007762528539821283\n",
      "32700 0.0077683546773586\n",
      "32800 0.007757234224686971\n",
      "32900 0.007772440723824169\n",
      "33000 0.007762154119686487\n",
      "33100 0.007754785996844234\n",
      "33200 0.0077390511353226926\n",
      "33300 0.007748427337395485\n",
      "33400 0.007735421470758236\n",
      "33500 0.007732006368543265\n",
      "33600 0.0077369689486525735\n",
      "33700 0.0077309506381282225\n",
      "33800 0.007734484420345876\n",
      "33900 0.007727496888087827\n",
      "34000 0.0077261342231466764\n",
      "34100 0.007733031060055169\n",
      "34200 0.007735998886851912\n",
      "34300 0.007723849270054467\n",
      "34400 0.00772379921860475\n",
      "34500 0.007721925143226478\n",
      "34600 0.007722282971376978\n",
      "34700 0.007722202336251014\n",
      "34800 0.007701579659308421\n",
      "34900 0.007697905642569574\n",
      "35000 0.0077044980594577804\n",
      "35100 0.007698943954898602\n",
      "35200 0.007699447331241304\n",
      "35300 0.007679040546607248\n",
      "35400 0.0076756937391744065\n",
      "35500 0.007675305124811394\n",
      "35600 0.0076762962320063854\n",
      "35700 0.00769417280931321\n",
      "35800 0.007676257171366378\n",
      "35900 0.0076712013424346396\n",
      "36000 0.007687424687970491\n",
      "36100 0.007677043207971089\n",
      "36200 0.00768853509528786\n",
      "36300 0.007679558004381206\n",
      "36400 0.007687642621006797\n",
      "36500 0.00767114895129347\n",
      "36600 0.007701197747490342\n",
      "36700 0.007669127369956193\n",
      "36800 0.007670051468532408\n",
      "36900 0.007667007630865805\n",
      "37000 0.007668244903555228\n",
      "37100 0.007667603720654392\n",
      "37200 0.007677745641280245\n",
      "37300 0.007671237486514732\n",
      "37400 0.007680733813393478\n",
      "37500 0.0076736578662568765\n",
      "37600 0.00768343630229054\n",
      "37700 0.007665302737259326\n",
      "37800 0.007692051939833488\n",
      "37900 0.007674356735700234\n",
      "38000 0.007655042250288819\n",
      "38100 0.0076515340457840855\n",
      "38200 0.007708987883801032\n",
      "38300 0.007665122002020043\n",
      "38400 0.007654603569322065\n",
      "38500 0.007659437393880663\n",
      "38600 0.007657569301686707\n",
      "38700 0.007663174877941187\n",
      "38800 0.007657095240623036\n",
      "38900 0.0076542072054630785\n",
      "39000 0.007652571993884894\n",
      "39100 0.007655477311593044\n",
      "39200 0.007664329979356362\n",
      "39300 0.007652491010387011\n",
      "39400 0.007652900404033284\n",
      "39500 0.00765729919917717\n",
      "39600 0.007645827778241939\n",
      "39700 0.007646778419584015\n",
      "39800 0.0076505899600726995\n",
      "39900 0.007646488836053493\n",
      "40000 0.007650083513680348\n",
      "40100 0.007655676437322808\n",
      "40200 0.007652214217272852\n",
      "40300 0.007641371111659037\n",
      "40400 0.00763921806351385\n",
      "40500 0.007637650302140892\n",
      "40600 0.0076345460889258926\n",
      "40700 0.007635785522671747\n",
      "40800 0.007619763643404163\n",
      "40900 0.00762564072375016\n",
      "41000 0.007624524656447128\n",
      "41100 0.007618488050722193\n",
      "41200 0.007622864174265489\n",
      "41300 0.007628958521276336\n",
      "41400 0.007618299213809213\n",
      "41500 0.007617554218344865\n",
      "41600 0.007617861865064547\n",
      "41700 0.007618171119156363\n",
      "41800 0.007620429408780261\n",
      "41900 0.007613394904064513\n",
      "42000 0.0076027722447026104\n",
      "42100 0.007609052440601329\n",
      "42200 0.007604108541430651\n",
      "42300 0.007605524420792858\n",
      "42400 0.007602612886875883\n",
      "42500 0.0076075469419171655\n",
      "42600 0.007598647591709412\n",
      "42700 0.007612213093133178\n",
      "42800 0.007597398320102363\n",
      "42900 0.007591441557366762\n",
      "43000 0.007590663542992838\n",
      "43100 0.007590319861368636\n",
      "43200 0.007591033773231566\n",
      "43300 0.007581616902375816\n",
      "43400 0.0075811905119252815\n",
      "43500 0.0075806779627322785\n",
      "43600 0.0075756582761443\n",
      "43700 0.007572285085573236\n",
      "43800 0.007579894579453839\n",
      "43900 0.007565640001598129\n",
      "44000 0.007558478526330553\n",
      "44100 0.007561030259761601\n",
      "44200 0.007555007993926096\n",
      "44300 0.007554531681478814\n",
      "44400 0.007554272328205405\n",
      "44500 0.007562002395830215\n",
      "44600 0.00756710941697068\n",
      "44700 0.007552956880371419\n",
      "44800 0.007563152820916902\n",
      "44900 0.007551912418425872\n",
      "45000 0.007551546201381061\n",
      "45100 0.007561596997313921\n",
      "45200 0.007549975382385658\n",
      "45300 0.007543184845974772\n",
      "45400 0.007542659588022322\n",
      "45500 0.007541970356967693\n",
      "45600 0.007552520695653184\n",
      "45700 0.007540646014614236\n",
      "45800 0.007547798726232364\n",
      "45900 0.007533536901380734\n",
      "46000 0.007531478541122267\n",
      "46100 0.00753640864805664\n",
      "46200 0.007542441892212705\n",
      "46300 0.007543881932626117\n",
      "46400 0.0075352261583614966\n",
      "46500 0.007532173483674905\n",
      "46600 0.007531781930661224\n",
      "46700 0.0075286759718282215\n",
      "46800 0.007535125379471768\n",
      "46900 0.007527968485995262\n",
      "47000 0.007528945179849675\n",
      "47100 0.007530071197495868\n",
      "47200 0.007526437530016118\n",
      "47300 0.007523041311834123\n",
      "47400 0.007525632519102558\n",
      "47500 0.0075333758705515745\n",
      "47600 0.007524737920372948\n",
      "47700 0.007519027543281464\n",
      "47800 0.00751899221358291\n",
      "47900 0.007518323152150301\n",
      "48000 0.007531486920554402\n",
      "48100 0.007499283476240813\n",
      "48200 0.007490828481237525\n",
      "48300 0.007494563711904035\n",
      "48400 0.007483801641565712\n",
      "48500 0.007483019100469398\n",
      "48600 0.007482684145473248\n",
      "48700 0.007482208853626093\n",
      "48800 0.007497083980925641\n",
      "48900 0.007481590032460785\n",
      "49000 0.007478602320462371\n",
      "49100 0.007463124743869871\n",
      "49200 0.00746482097003706\n",
      "49300 0.007459155252777718\n",
      "49400 0.0074587598478488915\n",
      "49500 0.007458422504848603\n",
      "49600 0.007460852157811793\n",
      "49700 0.007463375888646942\n",
      "49800 0.007463008626574669\n",
      "49900 0.007457473461076615\n",
      "50000 0.007462628902722352\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "parameters, costs = train(X_train, y_train, hidden_layers=[32, 16, 12, 10], alpha=0.1,\n",
    "                          batch_size=128, parameters=None, epochs=50000, verbose=100)\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['num_of_layers', 'W1', 'b1', 'W2', 'b2', 'W3', 'b3', 'W4', 'b4', 'W5', 'b5'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361.04720673163735"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(toc - tic) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A0 = X_test.T\n",
    "A0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test.T\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, _ = feedforward(A0, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.90662889e-01, 1.38325028e-01, 3.24041331e-10, ...,\n",
       "        9.90665067e-01, 7.77714874e-10, 1.95109078e-07],\n",
       "       [2.94259278e-05, 7.73839538e-02, 3.37333952e-07, ...,\n",
       "        2.94152008e-05, 1.49961615e-06, 6.52007991e-05],\n",
       "       [2.75406868e-11, 4.62077125e-11, 1.81824919e-06, ...,\n",
       "        2.75415880e-11, 3.30764724e-08, 7.19728090e-07],\n",
       "       ...,\n",
       "       [4.46661299e-06, 9.33492845e-05, 1.16412320e-06, ...,\n",
       "        4.46724221e-06, 1.49314079e-06, 3.95516299e-04],\n",
       "       [4.01702218e-04, 2.50572904e-05, 6.36231741e-05, ...,\n",
       "        4.01879802e-04, 1.26885265e-04, 4.23965055e-10],\n",
       "       [7.73229052e-06, 8.69192220e-07, 1.34459906e-03, ...,\n",
       "        7.73456823e-06, 8.69566969e-06, 2.07059227e-07]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      1000\n",
      "           1       0.91      0.92      0.91      1000\n",
      "           2       0.97      0.97      0.97      1000\n",
      "           3       0.98      0.98      0.98      1000\n",
      "           4       0.97      0.98      0.97      1000\n",
      "           5       0.97      0.97      0.97      1000\n",
      "           6       0.99      0.97      0.98      1000\n",
      "           7       0.98      0.99      0.98      1000\n",
      "           8       0.98      0.99      0.98      1000\n",
      "           9       0.98      0.97      0.97      1000\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_labels_pred = binarizer.inverse_transform(y_pred.T)\n",
    "print(classification_report(test_data[output], my_labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a124fbcf8>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(X, y, hidden_layers, alpha=0.9, epochs=20000, parameters=None, verbose=100):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    layers = [X.shape[0]] + hidden_layers + [y.shape[0]]\n",
    "\n",
    "    if parameters == None:\n",
    "        parameters = initialize_weights(layers)\n",
    "    \n",
    "    costs = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        ### Shuffling ###\n",
    "        indices = np.arange(X.shape[1])\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        X = X[:, indices]\n",
    "        y = y[:, indices]\n",
    "\n",
    "        #################\n",
    "\n",
    "        y_true = y\n",
    "\n",
    "        y_pred, cache = feedforward(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(y_true, y_pred)\n",
    "        \n",
    "        gradients = backpropagation(y_true, y_pred, cache, parameters)\n",
    "\n",
    "        for i in range(1, parameters['num_of_layers'] + 1):\n",
    "            assert parameters[f'W{i}'].shape == gradients[f'dW{i}'].shape, 'Size Mismatch'\n",
    "            assert parameters[f'b{i}'].shape == gradients[f'db{i}'].shape, 'Size Mismatch'\n",
    "\n",
    "        # update weights\n",
    "        parameters = update_parameters(parameters=parameters, gradients=gradients, alpha=alpha)\n",
    "\n",
    "        costs.append(cost)\n",
    "\n",
    "        if epoch % verbose == 0:\n",
    "            print(epoch, cost)\n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "parameters, costs = train(X_train, y_train, hidden_layers=[32, 16], alpha=0.99,\n",
    "                          parameters=None, epochs=1000, verbose=1)\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(toc - tic) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = X_test.T\n",
    "A0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test.T\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, _ = feedforward(A0, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_labels_pred = binarizer.inverse_transform(y_pred.T)\n",
    "print(classification_report(test_data[output], my_labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Code.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
